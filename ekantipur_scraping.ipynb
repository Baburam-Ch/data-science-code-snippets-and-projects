{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ekantipur scraping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjMf+yrAbmqsxWPxHJ/seo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baburam-Ch/data-science-code-snippets-and-projects/blob/master/ekantipur_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping the ekantipur (for learning purpose only)"
      ],
      "metadata": {
        "id": "PSVXxwaWh6-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ],
      "metadata": {
        "id": "5qGQkkE_PMmm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting html text from the url\n",
        "def get_html_doc(url):\n",
        "  return requests.get(url).content"
      ],
      "metadata": {
        "id": "JZ-BgpT9Ppt8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing the obtained html text from the url\n",
        "def parse_html_doc(html_doc):\n",
        "  return BeautifulSoup(html_doc, 'html.parser')"
      ],
      "metadata": {
        "id": "fhEjiJYGPxOj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetching the individual article from the site\n",
        "def get_data(soup):\n",
        "  articles = []\n",
        "  raw_soup = soup.find('div', class_=['col-xs-10', 'col-sm-10', 'col-md-10'])\n",
        "  raw_data = soup.find_all('article', attrs={'class':'normal'})\n",
        "  for data in raw_data:\n",
        "    d = {}\n",
        "    d['article_title'] = data.h2.a.text\n",
        "    d['article_link'] = data.h2.a['href']\n",
        "    d['article_author'] = data.find('div', attrs={'class':'author'}).a.text\n",
        "    d['article_text'] = data.p.text\n",
        "    articles.append(d)\n",
        "  return articles"
      ],
      "metadata": {
        "id": "F4QbljWgP53z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting all articles from the url/site with single method\n",
        "def get_article(path):\n",
        "  html_text = get_html_doc(path)\n",
        "  soup = parse_html_doc(html_text)\n",
        "  return get_data(soup)\n",
        "  "
      ],
      "metadata": {
        "id": "jEssQJaqUGsT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writing articles to csv file\n",
        "def write_to_csv(article, filename):\n",
        "  fieldnames = list(article[0].keys())\n",
        "  with open(filename, 'w') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for data in article:\n",
        "      writer.writerow(data)"
      ],
      "metadata": {
        "id": "QWlHiFqlXowr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = 'https://ekantipur.com/'"
      ],
      "metadata": {
        "id": "n4jSRriThJr7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAMACHAR SECTION"
      ],
      "metadata": {
        "id": "zFk2iWMrPF4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OnXgKfURO3w1"
      },
      "outputs": [],
      "source": [
        "samachar_articles = get_article(base_url + 'news')\n",
        "samachar_filename = 'samachar.csv'\n",
        "write_to_csv(samachar_articles, samachar_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARTHA/BANIJYA"
      ],
      "metadata": {
        "id": "mwrcVuIJZMlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artha_articles = get_article(base_url + 'business')\n",
        "artha_filename = 'artha.csv'\n",
        "write_to_csv(artha_articles, artha_filename)"
      ],
      "metadata": {
        "id": "LW9ex2CaPfRL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BICHAR"
      ],
      "metadata": {
        "id": "SQGK-5zKZg-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bichar_articles = get_article(base_url + 'opinion')\n",
        "bichar_filename = 'bichar.csv'\n",
        "write_to_csv(bichar_articles, bichar_filename)"
      ],
      "metadata": {
        "id": "UwbaOqvYZfWm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KHELKUD"
      ],
      "metadata": {
        "id": "g4aDY_USaCQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "khelkud_articles = get_article(base_url + 'sports')\n",
        "khelkud_filename = 'khelkud.csv'\n",
        "write_to_csv(khelkud_articles, khelkud_filename)"
      ],
      "metadata": {
        "id": "JMhh2MNPZ9lS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4YI8dUicaRwJ"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}